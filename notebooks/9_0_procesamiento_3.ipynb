{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesamiento de datos 3\n",
    "\n",
    "Debido a las limitaciones de recursos, se han tomado las siguentes decisiones para hacer mas ligero el software.\n",
    "\n",
    "1. Reducir el tamaño de las imagenes. Originalmente, el tamaño de las imagenes era 1204 x 1701 px, vamos a reducir a cortar las imagenes en dos y a reduciar hasta un tamaño de 1200 x 850 px\n",
    "2. Cambiar de imagenes a color a imagenes RGB\n",
    "\n",
    "Con estos dos cambios se aprovecharan mejor los recursos y se podran presentar resultados\n",
    "\n",
    "Ademas de las anteriores, tambien se tienen en cuanta las siguentes:\n",
    "\n",
    "1. Se volvera a recortar, ahora a 600 px x 850 x\n",
    "2. Se agregara la utilidad `tf.keras.preprocessing.image.ImageDataGenerator` la cual permitirá aumentar de forma artifical nuestra dataset y agregarle mas variedad al entrenamiento\n",
    "\n",
    "El plan de trabajo ahora sera de la siguente forma\n",
    "1. Se introducira la imagen de tamaño completo, es decir, 1204 x 1700\n",
    "2. Se cortara en 4 partes\n",
    "3. Cada una de estar partes será procesada por la red neuronal\n",
    "4. Se uniran para recuparar toda la información del principio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Redimensionar y recortar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-25 10:44:37.696575: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "CURRENT_DIR = Path('.').resolve()\n",
    "MODULES_DIR = CURRENT_DIR.parent.joinpath('src')\n",
    "sys.path.append(str(MODULES_DIR))\n",
    "DATA_DIR = CURRENT_DIR.parent.joinpath('data')\n",
    "\n",
    "import vis\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "# Recortar imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_clean = sorted([f for f in DATA_DIR.joinpath('CLEAN').iterdir() if f.is_file()])\n",
    "for file in files_clean:\n",
    "    vis.recortar_imagen_vertical(file,600,DATA_DIR.joinpath('Recortadas','CLEAN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_BLURR = sorted([f for f in DATA_DIR.joinpath('BLURR').iterdir() if f.is_file()])\n",
    "for file in files_BLURR:\n",
    "    vis.recortar_imagen_vertical(file,600,DATA_DIR.joinpath('Recortadas','BLURR'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "# Continuación\n",
    "\n",
    "Nuestro siguente paso será crear una red neuronal mas pequeña que pueda restuarar los archivos, posteriormente vamos a crear una una aplicacion que recorte automaticamente una imagen completa, procese por separa cada _recorte_, una vez procesado las unirá y terminará generando una imagen correcta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural-network",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
